\chapter{Appendix}
\label{ch:appendix}

\section{Nomenclature}
\label{sec:nomenclature}

\subsection{Gene nomenclature}

Although a discussion of nomenclature may be pedantic, unambiguous nomenclature is important to avoid confusion and misinterpretation of scientific results, as exemplified by a retracted Nature publication \citeref{kawasaki03}. This thesis uses standard notations commonly seen in the literature to distinguish between genes and proteins from different species, but not all publications (including those cited herein) use the notations presented here. For the most part, gene symbols serve merely as identifiers for genes in this thesis; accordingly, full gene names are usually not provided. (In particular, some genes such as \gene{AKT1} have no full names due to the systematic nature of their discoveries.) Genes are often known by several names owing to multiple discoveries in different research laboratories. Although one unique symbol has to be used to refer to a gene, genes often have pleiotropic functions, and some researchers prefer to refer to a gene by a particular alias that reflects one facet of gene function of interest. Other genes were initially assigned generic names such as p21, p27, p53 (referring to proteins with masses 21 kDa, 27 kDa, and 53 kDa, respectively), and these names have become standard in the literature. This thesis instead uses official gene symbols to ensure that genes can be uniquely identified and that no unfortunate misinterpretation will arise, as in the study of Kawasaki \emph{et al} \citeref{kawasaki03}. To learn more about a particular gene, readers may wish to query the Entrez Gene database ({http://www.ncbi.nlm.nih.gov/gene}).

As much as possible, official gene symbols as approved by the Human Genome Organisation Gene Nomenclature Committee or the Mouse Genome Informatics are used, and where appropriate, followed by common gene name aliases in parentheses. Human gene symbols appear in uppercase, and mouse gene symbols, in title case. Italicized names refer to genes, whereas non-italicized names refer to gene products. For example, the human gene on chromosome 9 (at location 98205264-98279247 of the GRCh37 human genome assembly) encoding the first family member of the patched 12-pass transmembrance receptor is denoted \gene{PTCH1}, and its protein counterpart, PTCH1. The mouse gene encoding the patched homologue gene is denoted \gene{Ptch1} and its protein, Ptch1. Specifically in this thesis, SHH and WNT usually refer to the molecular subgroups of medulloblastoma and not the proteins.

\subsection{Animal model nomenclature}

The nomenclature for genetically engineered mouse models is extensive \citeref{mgi13, mgi14}. This thesis will use the following simplified notation: \gene{Ptch1}\high{-/-} is homozygous mutant, \gene{Ptch1}\high{+/-} is heterozygous mutant, and \gene{Ptch}\high{+/+} is homozygous wildtype at the \gene{Ptch} locus. The (+) symbol denotes a wildtype or non-mutated allele, and the (-) symbol denotes a null or loss-of-function allele. Multiple genetic modifications are separated by space: \gene{Ptch}\high{+/-} \gene{Trp53}\high{+/-} is heterozygous mutant for both \gene{Ptch} and \gene{Trp53}. While these notations omit the mouse strain, the genetic background of the mouse model can indeed modulate the mutant phenotype \citeref{pazzaglia04}.


\section{Classification}
\label{sec:classification}

Classification is the central preoccupation of one of the oldest discipline, taxonomy, which seeks to place organisms into groups based on shared characteristics. Just as classifying organisms facilitate their study, classifying diseases also helps clinicians understand common mechanisms underlying and develop rational treatment against each type of disease. Classification encompasses two parts: first, the classes are established by exploring features and grouping the samples based on similarity of features; second, a method is created to classify new sample using features that discriminate between classes. In bioinformatics, the first part is referred to as \emphterm{class discovery}, and the second, \emphterm{class prediction}. In taxonomy, the term \emphterm{classification} only refers to the first part while the term{identification} refers to the second part. In machine learning, the first part is equivalent to \emphterm{unsupervised learning}, and the second, \emphterm{supervised learning}. In statistics, the term \emphterm{classification} only refers to the second part. Notwithstanding the different terminologies in various fields and the conflation of different meanings of the term `classification', the two components have distinct objectives. While some algorithms can be used for both class discovery and class prediction, algorithms specifically designed for prediction usually excel in class prediction. Furthermore, class prediction algorithms are well developed for the case in which the classes are known for a set of samples. Conversely, the class discovery process may be contentious: when using different features results in discovering different sets of classes, which set of classes is correct? Indeed, a classification system is practically useful insofar as it is widely accepted and stable. Once such a classification system is discovered and becomes established, one can focus on predicting the class of a new sample (as least until a new classification system arises).

\subsection{Class discovery}

The objective of class discovery is to group (or split) samples into disjoint classes. One systematic and unbiased way of achieving this goal is by \emphterm{clustering} (or \emphterm{partitioning}) a set of samples. Given measurements for various features (characteristics), clustering groups samples with similar features together, whereas partitioning split the samples into dissimilar groups. The distinction between clustering and partitioning is moot because the same overall objectives are achieved; however, different algorithms often produce different results.  A variety of clustering (or partitioning) algorithms are available, including hierarchical clustering, $k$-means, self-organizing map, affinity propagation, spectral clustering, graph clustering, mixture models, and consensus clustering. The two most popular clustering algorithms are hierarchical clustering and $k$-means (these are also among the oldest). These clustering algorithms have many additional variants. Hierarchical clustering may be divisive or agglomerative; it may calculate distance between groups using various \emphterm{linkage methods} (single, complete, average or others). $k$-means have variants such as $k$-medians or $k$-medoids, where different methods are used to represent the center of a group. $k$-means uses the mean of all the group members (i.e. centroid), $k$-medians uses the median, and $k$-medoids uses the group member whose average distance to all other group members is minimal. A variant of $k$-medoids is \emphterm{partitioning around medoids}, which uses a particular method for initializing the groups and updating the clusters. Furthermore, the aforementioned clustering methods may use different measures of distance between individual samples. Self-organizing map, affinity propagation, and spectral clustering are less popular in computational biology (at least for now). Graphic clustering encompasses a myriad of algorithms that cluster a \emphterm{graph} (a collection of nodes with interconnecting edges, known more informally as a `network'). These algorithms rely on known independence (lack of edges) between samples (nodes), whereas most of the other algorithms consider connections between all pairs of samples as presented in a distance matrix or similarity matrix. Mixture models attempt to model the data as a mixture of statistical distributions, such as multivariate Gaussian distributions, and the class assignments are probabilistic. Consensus clustering runs multiple clustering algorithms or variants (with different parameters) to generate multiple clustering results; then, it define classes based on the census of the clustering results. A type of consensus clustering algorithm that has gained popularity in recently is \emphterm{\gls{nmf}} consensus clustering. In this method, the data matrix is randomly factorized into two matrices using \gls{nmf} and samples assigned preliminary groups based on one of the factor matrices (using an arbitrary rule); subsequent to multiple \gls{nmf} runs, the clustering results are combined using consensus clustering, by apply hierarchical clustering on the census matrix, which counts the number of times that each pair of samples are assigned the same group.

The foremost decision in class discovery is deciding which type of features to use. For example, one could run clustering analysis with expression data, DNA methylation data, gene mutation data, patient, and other data. One could also combine different types of features and perform clustering in an integrative manner (taking care to weight the different types appropriately). Due to the exploratory nature of class discovery, there are no formal guidelines for the choice of features (though interval-scale features are more mathematically amendable to clustering analysis than nominal-scale features). Often, the type of features can be chosen to discover classes for specific objectives, such as using expression classes to identify tumour types with activation of different biological pathways. Indeed, a rational researcher would be unlikely to group patients into classes based on their birth days, months, and years for the same research objective. 

Another challenge of clustering analysis is to determine the number of classes represented in the data, $k$. Some algorithms begin by putting all samples into one class and proceed to partition the samples into smaller classes recursively (e.g. divisive hierarchical clustering), some algorithms begin by putting each sample into its own class and proceed to cluster the samples into bigger classes recursively (e.g. agglomerative hierarchical clustering). Either way, a decision must be made as to when to stop partitioning or clustering. In the case of hierarchical clustering, this decision is usually made informally. Other algorithms require the number of classes $k$ to be specified \emph{a priori} (e.g. $k$-means, finite mixture models). One recent algorithm that circumvents this requirement is Dirichlet process mixture model, which allows for all possible values of $k$ and discovers $k$ from the data. However, Dirichlet Process can be very computationally intensive to implement. An alternative approach is evaluate the clustering results for different values of $k$. (For algorithms in which $k$ is not specified \emph{a prior}, one runs the algorithm until $k$ clusters are created.)

There is no census on the best method for evaluating the quality of the clusters. Often, practitioners evaluate clustering results by considering external information. This external evaluation of the data should be done with care in order to avoid overfitting and optimistic bias. Additionally, since the objective of class discovery is to discover new classes, comparison with known classes would not likely help guide the evaluation of clustering results. As an example, suppose we evaluate clustering results by assessing the association of the discovered classes with survival (i.e. how different are the survival times among the classes). Using this criterion, we compare the association with survival among different clustering algorithms or parameter settings, and we choose the algorithm with the parameter setting that achieves the most significant association with survival. Unless we have additional samples not used in clustering to validate the association of the classes with survival, we may be \emph{overfitting} the algorithm (or parameter) to the existing data, and the optimistically biased association may disappear in a new dataset. In other words, we may have discovered classes that are spuriously associated with survival in our available data, and we may not observe this association again in a new dataset. We may mitigate this problem by using a subset of the data for optimizing the clustering algorithm and evaluating the results on the remaining data. Alternatively, we may also evaluate the clustering results without using external data. This internal evaluation of the data involves measuring the distance between sample pairs within each cluster as well as the distance between sample pairs from different clusters. The best cluster assignments should minimize the within-cluster distance and maximize the between-cluster distance. Different measures for evaluating and combining these two objectives have been proposed, including the silhouette width and the Dunn index. However, these internal measures depend on the definition of distance between samples: the results would change if a different distance measure were used. Indeed, evaluating the results of a clustering algorithm can be difficult and far from straightforward. Due to this difficulty in evaluating clustering results, there is also no census on the best clustering method. There is simply no substitute for applying class discovery on different datasets and confirming that the same classes are discovered in each dataset.

\subsection{Class prediction}

Given a set of samples with known classes (labeled data), the objective of class prediction is to learn the association between the labels and the features of the samples and subsequently predict the class of a new sample. Whether the classes labels could be defined by expert opinion, discovered by systematic clustering, or determined by other means. Class prediction involves three steps: \emphterm{training}, \emphterm{testing}, and \emphterm{application}. That is, a classifier must be trained on a labeled dataset and tested on another labeled dataset before it can be applied on samples with unknown classes (unlabeled data). During training, the classifier learns the association between labels and features in a first dataset (training data). During testing, we evaluate how well the classifier generalizes its learned association to new data (testing data). Finally, only when we are certain that the classifier can predict classes accurately, we apply it to unknown samples and make downstream decisions.

One simple measure of classifier performance is accuracy: the percentage of samples classified correctly. A high accuracy on the training data indicates the classifier has sufficient capacity to learn from the data, and a high accuracy on the testing data implies that the classifier can generalize well. When a classifier has high training accuracy but low testing accuracy, the classifier is likely overfitted to the training data. In such an event, possible remedies include simplifying the complexity of the classification algorithm (by permitting fewer free parameters) or collect more training data.

For a classification problem with two classes (positive and negative), common evaluation methods include receiver-operating characteristics curve or precision-recall curve. These methods simultaneously evaluate how often a classifier falsely assign a positive label to a true negative sample and how often a classifier falsely assign a negative label to a true positive sample. For multiclass problems, common evaluation methods include Rand index or Jaccard index. Alternatively, a multiclass problem can be split into multiple two-class sub-problems, in which each sub-problem addresses whether a sample belongs to a given class.


\section{Prognostic biomarker discovery}
\label{sec:prognostication}

\subsection{Log-rank tests vs. Cox proportional-hazards test}

The survival analyses presented were based on log-rank tests and Cox proportional-hazards tests, which may yield considerably different p-values. As log-rank tests do not assume proportional hazards, their results were presented instead of those of Cox proportional-hazards tests. Univariate Cox proportional-hazards analyses were performed to estimate hazard ratios and sample sizes required for prospective studies.

\subsection{Construction and validation of risk stratification models}

In order to identify novel and robust prognostic biomarkers, the present study examined a discovery set and a validation set of medulloblastoma cases. The discovery set consisted of cases with patient survival follow-up, whole-genome copy-number profiles, and varying degree of clinical details, including age, gender, metastatic status, and histological subtype. This set of cases was acquired from several hospitals and tumour banks around the globe. Therefore, the patients in the discovery set represent a heterogeneously treated group with diverse ethnic backgrounds. In contrast, the validation set consisted of medulloblastoma patients who were uniformly treated at a single institution in Moscow (Burdenko Hospital).

All available clinical variables and molecular markers were tested for prognostic association in the discovery set. Several clinical variables, such as metastatic status and age group, were categorized in multiple different ways, due to disagreements in the literature and clinical practice across continents. Due to the large number of candidate markers tested, a rigorous selection procedure was applied in order to select a small number of candidates to be validated in the external validation set using fluorescence in situ hybridization (FISH), which is routinely performed in modern pathology laboratories within hospitals.

Accordingly, the clinical and molecular candidate biomarkers were assessed by three approaches. First, the candidates were assessed by a cross-validation method, in order to estimate the expected validation rate of the biomarker. That is, whether the biomarker will likely validate in an independent cohort. Second, the sample size required for further validation in a prospective study was estimated for each candidate. Prognostic markers with small effect size (i.e. hazard ratio) or with low frequency may need impractically large sizes and are thus clinically irrelevant. Third, the candidates were combined in multivariate Cox proportional-hazards models in order to assess whether the biomarkers have prognostic values independent of one another. Biomarkers were prioritized by high validation rates, reasonably small sample sizes, and/or prognostically significance in multivariate models. The selected biomarkers were then used to construct the risk stratification models for each medulloblastoma subgroup.

The proposed risk stratification models represent promising candidates for future prospective trials. The constituent biomarkers were selected based on analyses within a heterogeneous discovery set, and are likely generalizable to different patient populations. For a specific treatment protocol within a specific patient population, there may be prognostic markers that have better prognostic value, particularly those that were not assessed in the present study due to scope. Notwithstanding these limitations, the proposed risk stratification models have been validated in an independent cohort, and can serve as the basis for the informed design of a future prospective trial.

\subsection{Rare cytogenetic events}

Some molecular biomarker candidates (e.g. \gene{MYC} amplification, chr17 gain) have only been observed in a relative small number of patients (~10). Notwithstanding their infrequency in specific subgroups of medulloblastoma (a rare disease), their prognostic significances are supported by log-rank tests, likely due to their large `effect sizeâ€™ (i.e. hazard ratio). Such biomarker candidates, however, have low expected validation rate from cross-validation and large estimated sample sizes from power analysis. On account of their potential therapeutic impact, these candidates were nonetheless included in the risk stratification models based on their independent prognostic significance under multivariate Cox models. Indeed, the candidates were ultimately validated to be \emph{bona fide} prognostic biomarkers in the external validation set.

\subsection{Isolated vs. non-isolated events}

Isolated arm events occur in the absence of whole-chromosome event; non-isolated events may occur in the context of a whole-chromosome event. In the appendix tables, chr17q|G denotes the gain of chr17q or gain of chr17, whereas chr17Q|G denotes the gain of chr17q without concurrent gain of the whole chr17.

\subsection{Isochromosome events}

The analyses of isochromosomes (e.g. iso17q) differ between the figures and the tables. In the tables, samples with iso17q were compared against samples without iso17q, irrespective of other cytogenetic aberrations on chr17. However, iso17q in Group4 medulloblastoma, albeit statistically significantly associated with poor survival in Group4 patients, have a low validation rate (Appendix Table 10), suggesting that its statistical association may be indirect. This statistical significance may be due to the inclusion of patients with tumors harboring chr17 gain in the reference group, since chr17 gain is associated with good prognosis (Figure 5A). Therefore, samples with iso17q were compared against samples with balanced chr17 and samples with broad gain or loss of chr17 were excluded from Figure 2G-H.


\section{Cancer treatment}

\subsection{Chemotherapy}

Chemotherapy is the use of drugs that target general cellular processes such as cell division in order to eradicate cancer cells. The drugs may damage DNA directly (by alkylation or forming DNA adducts), interfere with DNA synthesis (by inhiting folic acid, substituting for a nucleotide, intercalating into DNA, or inhibiting topoisomerase), prevent mitosis (by inhibiting microtubules), or various other mechanisms. Often, chemotherapy relies on triggering the (hopefully intact) apoptotic program of the cell in response to recognition of DNA damage. For example, loss-of-function mutation in \gene{TP53} (responsible for triggering apoptosis) can lead to resistance against chemotherapy. Overexpression of efflux pumps is another major mechanism of chemoresistance.

Chemotherapeutic treatment typically lasts from weeks to months, and it is given at different stages. The purpose of induction chemotherapy is to induce a remission, while consolidation chemotherapy is given, typically at high-dose, at the end of induction to complete remission. Conversely, maintenance chemotherapy is given at lower doses to prevent cancer recurrence.

Sometimes chemotherapy are described as adjuvant or neoadjuvant. Adjvuant therapy is given to assist the main treatment in eradicating the cancer and is given during or after the latter; neoadjuvant therapy is given before the main treatment. In solid tumours, some literature consider surgical resection as the main treatment while others consider radiotherapy.
