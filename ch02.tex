\chapter{Molecular classification of medulloblastoma for clinicians}
\chaptermark{Molecular classification}
\label{ch:mb-class}

\begin{objective}
To develop a clinically applicable method for molecular classification of medulloblastoma.
\end{objective}

Medulloblastoma can be classified by similarities in RNA expression profiles into four molecular subgroups: WNT, SHH, Group3, and Group4. These four subgroups show some association with the histological subtypes of medulloblastoma: classic, demosplastic, and anaplastic (large cell). The demosplastic histotype is enriched in SHH medulloblastoma (i.e. it is observed more often than expected by chance), while the anaplastic histotype is enriched in Group3 medulloblastoma. Nonetheless, the molecular classification is quite different from the histological classification. Despite its relative infancy, the molecular classification of medulloblastoma has gained widespread acceptance in the research community since the publication of the Taylor \emph{et al.}\ \citeref{taylor12}, a report of the consensus on classifying medulloblastoma by molecular profiles. Prior to this consensus report, several groups have independently discovered various molecular subtypes of medulloblastoma using different clustering analyses (hierarchical clustering and \gls{nmf} consensus clusterin) for class discovery \emph{thompson06, kool08, northcott11a, remke11}. On the surface, these studies discovered different molecular subtypes; in fact, each study discovered a different number of subtypes. Upon closer inspection, all the studies reported the delineation of a \gls{shh} activated and a \gls{wnt} activated subtype. Further, most studies (those with sufficient sample size) discovered at least two additional molecular subgroups; the exact number of molecular subtypes discovered depended on the granularity of the clustering or partitioning analysis. Indeed, the number of molecular subtypes is not as biologically important as the existence of each molecular subtypes. (Refer to the \emphlab{Classification} section, page \pageref{sec:classification}, in the \emphlab{Appendix} for a discussion on the difficulty in determining the number of classes.) In fact, most studies identified molecular subtypes bearing semblance to the GroupC and GroupD subtypes discovered by Northcott \emph{et al.}\ \citeref{northcott11a}, which have been renamed Group3 and Group4, respectively. To emphasize, each of the currently accepted WNT, SHH, and Group3, Group4 molecular subgroups have been identified in multiple studies, and these subgroups represent molecular entities that differ genetically, epidemiologically, and clinically \citeref{taylor12}.

We sought to develop a method for classifying medulloblastoma samples into the four molecular subgroups. This method consists of two components: an experimental assay for measuring marker expression and a computational classifier for assigning molecular subgroup to an unknown medulloblastoma sample. We used the nanoString nCounter technology \citeref{geiss08} to directly measure the expression level of 22 subgroup-specific marker genes, each of which is overexpressed in one of four molecular subgroups. We then selected the optimal classification algorithm from a panel of algorithms by comparing accuracy during cross-validation. Subsequently, we validated the trained classifier on external datasets of medulloblastoma samples with independently assigned molecular subgroups.

We did not use expression microarrays for measuring RNA expression because they have long been considered tools ill-suited for clinical testing. While the aforementioned class-discovery studies used expression arrays (Affymetrix U133 or Exon ST 1.0) to measure the expression of all protein-coding genes (roughly 20~000), we only needed for our purpose to measure the expression of genes that help discriminate between the molecular subgroups.  Reducing the number of genes to be measured simultaneously reduces the number of probes during hybridization, which in turn mitigates the potential for cross-hybridization (binding of probes to sequences other than the target sequence). Critically, expression microarrays typically require fresh frozen samples and perform poorly on \gls{ffpe} samples. Even on microarray platforms specifically designed for \gls{ffpe} samples, the quality of the RNA from \gls{ffpe} samples are generally poor. Formalin fixation and paraffin embedding preserve cellular and tissue architecture but cause extensively degradation of nucleic acids, especially RNA. Further, microarrays are plagued by complex and diverse preprocessing procedures (probe signal normalization and subsequent processing), and experiment-specific effects (batch effect and centre-specific effect. All these limitations abrogates the widespread adoption of microarrays in diagnostic laboratories. Conversely, the nanoString technology is less sensitive to RNA degradation and provides high reproducibility between experiments.

The nanoString platform provide high-quality measurements of RNA expression and differs from expression microarrays in important ways \citeref{geiss08}. In nanoString, the probes are custom designed to a relatively small set of target gene transcripts, and the cross-hybridization limitation of microarrays is circumvented by reducing the number of hybridization targets. nanoString measures transcript abundance directly while expression microarrays require \emph{in vitro} transcription (or reverse transcription) and \gls{pcr} amplification. These enzymatic reactions can introduce bias (e.g. GC content bias) and variation (e.g. stochastic amplification by \gls{pcr}). Additionally, transcripts are detected by the simultaneously binding of a pair of nanoString probes (a fluorescent-labeled reporter probe and a biotinylated capture probe) in solution (i.e. 3-dimensional space); for expression arrays in comparison, each target sequence binds to one immobilized probe on a 2-dimensional surface (chip or bead). (Mismatch probes present in the older microarray designs such as Affymetrix U133 are often ignored during data normalization, and they have been eliminated in newer designs such as Affymetrix Exon ST 1.0.) These differences in hybridization allows nanoString to achieve higher specificity and sensitivity, especially for \gls{ffpe} tissue.

While clustering analysis has been instrumental in \emph{discovering} the molecular classes of medulloblastoma, it is ill-suited for predicting the class of a new, unknown sample. (See page \pageref{sec:classification} for the distinction between class discovery and class prediction.)  Clustering analysis can be sensitive to changes in sample size: removal or additional samples can drastically change the clustering results. The inclusion of samples with poor quality measurements may also completely reorganize the clustering structure. Moreover, clustering analysis is particularly prone to batch effects, where the discovered classes represent different technical batches of samples and do not reflect underlying biology. In comparison, class prediction can mitigate these effects by selecting for features that discriminate between the different classes and by assessing training and testing accuracies separately. Admittedly, clustering algorithms can be adapted for class prediction, but existing classification algorithms are widely applied, extensively tested, and well understood. Further, model-based classifiers can be designed under the classification framework in order to exploit specific statistical properties of the input data and thus improve prediction accuracy. Above all, we prefer to use or refine an ready suitable tool rather than re-purposing a tool designed for another task.

We show that our method can accurately predict the molecular subgroup of medulloblastoma samples. The method is reproducible across different nanoString service centres and across different datasets. The assays only cost about \$50 a sample at a throughput up to 100 samples a week. Thus, we have developed a molecular subgrouping method that is rapid, reliable, and reproducible, and the method can be readily adopted for use in a diagnostic laboratory.


\section{Materials and methods}

\subsection{Patient samples}

All samples were obtained in accordance with the Research Ethics Board at the Hospital for Sick Children (Toronto, Canada).  Primary medulloblastomas comprising the training series for nanoString ($n = 101$) have been previously described.  Samples contributing to the validation series ($n = 131$) have been previously described and were obtained as total RNA extracted from fresh-frozen tissue from the DKFZ (Heidelberg, Germany; Remke series, $n = 56$) \citeref{remke11}, the Dana-Farber Cancer Institute (Boston, USA; Cho series, $n = 39$) \citeref{cho11}, and Marcel Kool (DKFZ, Heidelberg, Germany; Kool series, n=36) \citeref{kool08}.  \gls{ffpe} cases ($n = 84$) were obtained as paraffin sections from the Hospital for Sick Children (Toronto, Canada; $n = 34$), John’s Hopkins University (Baltimore, USA; $n = 25$), and the DKFZ (Heidelberg, Germany; $n = 25$).

\subsection{Tissue sample processing}

Total RNA was extracted from fresh-frozen tissue using the Trizol method (Invitrogen) according to the manufacturer’s instructions.  For FFPE samples, 3 to 5 paraffin sections per sample were first deparaffinized with xylene prior to RNA extraction using the RNeasy FFPE kit (Qiagen) as directed by the manufacturer.  RNA concentration was measured using a Nanodrop 1000 instrument (Nanodrop). Paul Northcott processed the samples.

\subsection{RNA integrity assessment}

RNA derived from FFPE material was analyzed with the Agilent Bioanalyzer to determine RNA integrity at \gls{tcag}. Smear analysis was performed using the Agilent 2100 expert software to determine the proportion of RNA C300 nucleotides (nt) within a given sample.

\subsection{nanoString CodeSet design and expression quantification}

Signature genes for each medulloblastoma subgroup were included in the CodeSet on the basis of their observed subgroup-specific expression as previously determined by Affymetrix exon array analysis.  The CodeSet was designed to consist of a total of 25 genes with 5 to 6 signature genes included for each subgroup: WNT (\gene{WIF1}, \gene{TNC}, \gene{GAD1}, \gene{DKK2}, \gene{EMX2}), SHH (\gene{PDLIM3}, \gene{EYA1}, \gene{HHIP}, \gene{ATOH1}, \gene{SFRP1}), Group3 (\gene{IMPG2}, \gene{GABRA5}, \gene{EGFL11}, \gene{NRL}, \gene{MAB21L2}, \gene{NPR3}), Group4 (\gene{KCNA1}, \gene{EOMES}, \gene{KHDRBS2}, \gene{RBM24}, \gene{UNC5D}, \gene{OAS1}).  Three housekeeping genes (\gene{ACTB}, \gene{GAPDH}, and \gene{LDHA}) were also included in the CodeSet for biological normalization purposes.  Probe sets for each gene in the CodeSet were designed and synthesized at nanoString Technologies. See Northcott \emph{et al.}\ \citeself{northcott12} for details on the subgroup-specific expression markers (note that Group C has been renamed Group3 and Group D has been renamed Group4 since the publication of this study).

Total RNA (100 ng) from fresh-frozen tissue and \gls{ffpe} material was analyzed using the nanoString nCounter Analysis System at the University Health Network Microarray Centre (Toronto, Canada), the Oncogenomics Core Facility at the University of Miami (Miami, USA), and the Frontiers in Genetics Facility at the University of Geneva (Geneva, Switzerland).  All procedures related to mRNA quantification including sample preparation, hybridization, detection, and scanning were carried out as recommended by nanoString Technologies.

\subsection{NanoString Data processing and class prediction}

Raw nanoString counts for each gene within each experiment were subjected to a technical normalization using the counts obtained for positive control probe sets prior to a biological normalization using the three housekeeping genes included in the CodeSet.  Normalized data were log2-transformed and used as input for class prediction analysis.

A series of medulloblastomas with known subgroup affiliation ($n = 101$) were used to establish a training dataset for subsequent class prediction analysis of independent cohorts utilized in the study.  Various class prediction algorithms were assessed by a 10-fold cross-validation scheme, using a set of scoring indices to establish a pipeline for prediction of medulloblastoma subgroups using nanoString data derived from the training series.  Based on superior performance in cross-validation analysis, the PAM method was selected for all downstream class prediction analyses.  A detailed summary of class prediction methods and evaluation of their performance are available in supplementary methods.

All class prediction analyses were performed in the R statistical programming environment (v2.13). Implementations of the class prediction algorithms were imported
from the following R packages: MASS v7.3 (linear discriminant analysis; LDA), class v7.3 (k-nearest neighbor; KNN), e1071 v1.5 (support vector machine; SVM), nnet v7.3 (multinomial log-linear model; MULT), and pamr v1.51 (prediction analysis for microarrays; PAM) \citeref{tibshirani02}. During cross-validation, the training set of 101 samples was randomly split into 10 partitions. Each class predictor was trained on nine of the partitions, and the performance of the predictor was subsequently tested on the one remaining partition. Each of the 10 partitions was used as the testing set in turn for a round of cross-validation, for a total of 10,000 rounds of cross-validation, which was
repeated three times with reproducible results.

The scoring indices used during testing were accuracy, Jaccard similarity index, Rand index, adjusted Rand index, and Fowlkes–Mallows index. The latter four indices are different indices for determining the similarity between
two groupings, which are the known and predicted classifications of samples in the current analysis. These indices serve as more stringent measures of accuracy in multi-class prediction. Aside from the accuracy measures (validity),
the reliabilities of the predictors were also determined using Shannon entropy as a measure of uncertainty. Predictors with varying predicted classes for the same sample across the cross-validation rounds have higher entropy values, and are hence less reliable.

Since the model parameters for SVM can affect the prediction performance, these parameters were optimized by a grid search in a separate round of cross-validation. The ranges of searched parameter values were: $[2^{-5}, 2^{15}]$ for \code{C}; $[2^{-15}, 2^3]$ for \code{gamma}; $[2, 8]$ for \code{degree}; $[-1, 1]$ for \code{coef0}. Further, SVM using different kernels (linear, radial basis, polynomial, and sigmoid) were assessed, and the kernel with the best performance was selected. Similarly for KNN, the best model was selected from models with different $k$.

\subsection{Regression analysis of prediction accuracy}

Cumulative prediction accuracy was modeled as a function of FFPE sample age. The prediction accuracies were first calculated for each sample age year-group. The cumulative accuracies were determined by calculating the cumulative sum of the accuracies, weighted by the size of each year-group. The data were fitted using a 5-parameter logistic regression model, as implemented in the drc v2.1 R package. The maximum asymptote parameter ($D$) was constrained at 1 in order to reflect the high accuracy the predictor achieved with recent FFPE samples.


\section{Results}

In order to select a classification algorithm that predicts most accurately and reliably, we evaluated the class prediction performance of a panel of well-known classifiers: \gls{svm}, \gls{lda}, multinomial logistic regression, \gls{knn}, \gls{pam}. (Note that \gls{pam} is to be distinguished from the clustering algorithm, partitioning around medoids; \gls{lda} is also to be distinguished from latent Dirichlet allocation, another unsupervised learning algorithm.)  These classifiers were trained on a training set of 101 fresh-frozen medulloblastoma samples with known molecular subgroups. Classifiers that have tuning parameters (\gls{svm}, \gls{pam}, and \gls{knn}) were tuned using a round of 10-fold cross-validation. The performance of all classifiers were assessed using repeated, stratified, 10-fold cross-validation using various measures of accuracy. \gls{pam} consistently showed superior performance to all other classifiers. Its predictions are most consistent across multiple rounds of cross-validation, indicating that its predictions are reliable. In comparison, multinomial logistic regression predicted different subgroups for the same sample when it was trained on different subsets of the training data, illustrating that it does not generalize well and its predictions are unreliable. Further, the test accuracy of the \gls{pam} algorithm as assessed by cross-validation was the highest. Admittedly, the test accuracies of all classification algorithms were high in roughly in the same range, though \gls{pam} consistently outperform all the other classifiers in repeated rounds of cross-validation.

Therefore, we proceeded to evaluate the performance of the trained \gls{pam} classifier on external datasets of medulloblastoma samples with independently assigned molecular subgroups. The original molecular subtypes from the previous studies were mapped to the consensus molecular subgroups using the mapping detailed in the consensus report \citeref{taylor12}. The performance of the trained classifier was tested on an external set of 130 fresh-frozen medulloblastoma samples. By testing on an external validation set that is disjoint from the training set, we show that our classifier generalizes well and is insensitive to irrelevant variability across datasets. Indeed, our method achieved an overall classification accuracy of 98\% (\citefig{nanostr-valid}).

\begin{figure}[hb]
	\begin{center}
		\includegraphics[width=\textwidth]{fig/nanostr-class/nanostr-valid.pdf}
	\end{center}
	\caption[Validation of classification assay on independent medulloblastoma cohorts]
	{
	Validation of classification assay on independent medulloblastoma cohorts.
	\textbf{a-c}, Expression heatmaps of nanoString class-predicted medulloblastomas of known subgroup status as published by Remke et al.\citeref{remke11} (a), Cho et al.\citeref{cho11} (b), and Kool et al.\citeref{kool08} (c). Samples are sorted according to subgroup predictions. Known expression subgroup affiliations and erroneously classified cases are marked above the heatmap.
	\textbf{d}, \emph{Left}, Pie chart depicting the known subgroup distribution of medulloblastomas from the three independent cohorts analyzed in \textbf{a-c} ($n = 130$) and the subgroups predicted by nanoString profiling. Misclassified cases are marked within each slice according to the predicted subgroups. \emph{Right}, Pie chart of class prediction accuracy ($127/130$) from the validation set. Adapted from Northcott et al.\citeself{northcott12}
	}
	\label{fig:nanostr-valid}
\end{figure}

Aside from being highly accurate, our method for determining molecular subgroups is also reproducible across multiple centres. Our method yielded reproducible predictions of molecular subgroups when the same samples were processed in three independent laboratories \citeself{northcott12}.

\clearpage

Furthermore, our classifier, which was trained on fresh-frozen training samples, continue to predict molecular subgroups accurately on \gls{ffpe} samples. Since fresh-frozen samples are generally rare in the clinical setting and most samples are only available in \gls{ffpe} archival form, our method would need to achieve acceptable performance on \gls{ffpe} samples if it is to be used in diagnostic laboratories. Indeed, the clinical applicability of our method was demonstrated by its high predictive accuracy on \gls{ffpe} samples of archival ages $\leq 8$ years (\citefig{nanostr-ffpe}). The accuracy decreased on older \gls{ffpe} samples, presumably due to poorer RNA integrity, though standard measurements of RNA quality were not correlated with accuracy \citeself{northcott12}. Taken together, these results suggest that any fresh frozen or recent \gls{ffpe} samples may be reliably assigned molecular subgroups using our classification method.

\begin{figure}[ht]
	\begin{center}
		\includegraphics[width=\textwidth]{fig/nanostr-class/nanostr-ffpe.pdf}
	\end{center}
	\caption[Classification performance on formalin-fixed paraffin embedded archival samples]
	{
	Classification performance on formalin-fixed paraffin embedded archival samples.
	\textbf{a}, Class prediction accuracy in relation to sample age of archival medulloblastomas stored as \gls{ffpe} material ($n = 84$). Samples obtained within the past 8 years exhibit accuracies of $\geq 95\%$, as demarcated by the red vertical line.
	\textbf{b}, Heatmap of nanoString data showing class predictions for \gls{ffpe} cases of $\leq 8$ years confidently predicted by the assay ($n = 28$). Samples are sorted according to subgroup prediction. All cases satisfying prediction probability threshold were assigned to the correct subgroup ($28/28$). Adapted from Northcott et al.\citeself{northcott12}
	}
	\label{fig:nanostr-ffpe}
\end{figure}


\section{Discussion}

We developed and validated a method for classifying medulloblastoma into molecular subgroups. We show that the method produces reproducible results across different centres and on different training datasets. Furthermore, the method performs well on \gls{ffpe}, allowing it to be readily adopted in a diagnostic laboratory. Our method has been published in Northcott \emph{et al.}\ \citeself{northcott12}.

Since the initial publication of this work, we have used the method to classify over 1000 medulloblastoma samples.  and identified a few cases were replicate assays yielded conflicting results. Further examination revealed that poor sample quality and suboptimal assay conditions likely contributed to classification discrepancies. Therefore, additional quality control measures were implemented, which are especially important for developing this assay further for \gls{clia} certification.

Given that standard measurements of RNA quality were insufficient for predicting assay accuracy \citeself{northcott12}, the mean signals of the endogenous control probes included in the nanoString assay were used to assess whether sufficient quantities of intact, undegraded were present in the samples, using a outlier detection method. A Gaussian mixture model was fitted to all collected nanoString data to establish the nominal range for mean endogenous-control signals. Samples with mean signals that deviate significantly from this range at a significance level of 0.01 were identified as outliers. Such samples, due to extensive RNA degradation, cannot be assigned a molecular subgroup, and they may require classification using DNA copy-number or methylation profiling.

Samples with sufficiently high-quality RNA may yet yield uninterpretable results when suboptimal assay conditions confound the measurements. Therefore, signals from positive control and negative control probes are examined to identify assay reactions that may have failed and hence produced unreliable measurements. The current collection of nanoString data was used to establishe the nominal range of positive and negative signals, using Gaussian mixture and multiple negative binomial models, respectively. As above, measurements that deviate significantly from the nominal range at a significance level of 0.01 were considered outliers. Samples that fail this quality control criterion may simply be run again.

Furthermore, multi-sample assays are not amendable to reproducible clinical analysis of samples in real-time, owing to time constraints and potential batch effects. Single-sample nanoString assays were therefore tested for concordance with previous results. With the appropriate quality control and improved normalization procedures implemented, 100\% concordance was achieved with single-sample assays, which further enhanced the clinical utility of molecular classification assay.



Above all, a rapid, reliable, and reproducible assay was developed for assigning molecular subgroups to clinical samples, available as frozen or recent \gls{ffpe} material, and this assay has been developed further use in a clinical laboratory. Critically, stringent quality control must accompany the nanoString classification assay, lest its potentials be shadowed by concerns of reproducibility and predictability, an ignominy that has long plagued the microarray technology \citeref{shi08,deronde10,weigelt10,ein-dor06,frantz05,michiels05,ioannidis05,marshall04,check04,tan03,tilstone03}.

As later chapters will show, the classification of medulloblastoma into WNT, SHH, Group3, and Group4 is both practically feasible but also catalyzes research into the molecular mechanism underlying medulloblastoma. Indeed, the molecular classification of medulloblastoma led to numerous discoveries by the community \citeself{shih14, shih12, perreault14, kool14, ramaswamy14, ramaswamy13, remke13, dey13, zhukova13, dubuc13, dubuc12, wu12, jones12}.


\clearpage
