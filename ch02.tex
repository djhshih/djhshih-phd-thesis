\chapter{Molecular classification of medulloblastoma for clinicians}
\chaptermark{Molecular classification}
\label{ch:mb-class}

\begin{objective}
We aim to develop a clinically applicable method for classifying medulloblastoma into molecular subgroups.
\end{objective}

Medulloblastoma can be classified by RNA expression profiles into four molecular subgroups: WNT, SHH, Group3, and Group4. These four subgroups show some modest association with the histological subtypes of medulloblastoma. The desmosplastic histotype is enriched in SHH medulloblastoma (i.e. it is observed more often than expected by chance), while the large cell/anaplastic histotype is enriched in Group3 medulloblastoma. Nonetheless, the molecular classification is quite different from the histological classification. Despite its relative infancy, the molecular classification of medulloblastoma has gained widespread acceptance in the research community since Taylor \emph{et al.}\ \citeref{taylor12} published a consensus report on classifying medulloblastoma by molecular profiles. Prior to this consensus report, several groups have independently discovered various molecular classes of medulloblastoma using different clustering analyses (hierarchical clustering and \gls{nmf} consensus clustering) for class discovery \citeref{thompson06, kool08, northcott11a, remke11}. On the surface, these studies discovered different molecular classes; moreover, each study discovered a different number of classes. Upon closer inspection, all the studies reported the delineation of a \gls{shh}-activated and a \gls{wnt}-activated molecular class. Furthermore, most studies (those with sufficient sample size) discovered at least two additional molecular classes; the exact number of classes discovered depended on the granularity of the clustering or partitioning analysis. Indeed, the number of molecular classes is not as biologically important as the existence of each molecular entity. (Refer to the \emphlab{Classification} section on page \pageref{sec:classification} in the \emphlab{Appendix} for a discussion on the difficulty in ascertaining the number of classes.) In fact, most studies identified molecular classes bearing semblance to the GroupC and GroupD subtypes discovered by Northcott \emph{et al.}\ \citeref{northcott11a}, which have been renamed Group3 and Group4, respectively. To emphasize, each of the currently accepted WNT, SHH, and Group3, Group4 molecular subgroups have been identified in multiple studies, and these subgroups represent molecular entities that differ genetically, epidemiologically, and clinically \citeref{taylor12}.

We sought to develop a method for classifying medulloblastoma samples into the four molecular subgroups. This method consists of two components: an experimental assay for measuring marker expression and a computational classifier for assigning molecular subgroup to an unknown medulloblastoma sample. We used the nanoString nCounter technology \citeref{geiss08} to directly measure the expression level of 22 subgroup-specific marker genes, each of which is overexpressed in one of the four molecular subgroups. We then selected the optimal classification algorithm from a panel of algorithms by comparing cross-validation accuracies. Subsequently, we validated the trained classifier on external datasets of medulloblastoma samples with independently assigned molecular subgroups.

We did not use expression microarrays for measuring RNA expression because they have long been considered tools ill-suited for clinical diagnostics \citeref{shi08, deronde10, weigelt10, ein-dor06, frantz05, michiels05, ioannidis05, marshall04, check04, tan03, tilstone03}. While the aforementioned class-discovery studies used expression arrays (Affymetrix U133 or Exon ST 1.0) to measure the expression of all protein-coding genes (more than 20~000), we only needed, for our purpose, to measure the expression of genes that help discriminate between the molecular subgroups.  Reducing the number of genes to be measured simultaneously reduces the number of hybridizing probes, which in turn mitigates the potential for cross-hybridization (binding of probes to sequences other than the target sequence) \citeref{bishop08, li05}. Critically, expression microarrays typically require fresh-frozen samples and perform poorly on \gls{ffpe} samples. Even on microarray platforms specifically designed for \gls{ffpe} samples, the signal-to-noise ratios of \gls{ffpe} samples are generally poor. Formalin fixation and paraffin embedding preserve cellular and tissue architecture but cause extensive degradation of nucleic acids, especially RNA. Furthermore, microarrays are plagued by complex and diverse preprocessing procedures (probe signal normalization and subsequent processing), in addition to experiment-specific effects (unwanted variations). All these limitations preclude the widespread adoption of microarrays in diagnostic laboratories. Conversely, the nanoString technology is less sensitive to RNA degradation and provides high reproducibility between experiments.

The nanoString platform provide high-quality measurements of RNA expression and differs from expression microarrays in important ways \citeref{geiss08}. In nanoString, the probes are custom designed to a relatively small set of target gene transcripts, and the cross-hybridization limitation of microarrays can be circumvented in part by reducing the number of hybridization targets and designing probes against non-homologous sequences \citeref{bishop08, li05, geiss08}. nanoString measures transcript abundance directly while expression microarrays require \emph{in vitro} transcription (or reverse transcription) and \gls{pcr} amplification. These enzymatic reactions can introduce bias (e.g. GC content bias) and variation (e.g. stochastic amplification by \gls{pcr}). Additionally, in an nanoString assay, transcripts are detected by the simultaneous binding of a pair of probes (a fluorescent-labeled reporter probe and a biotinylated capture probe) in solution (i.e. 3-dimensional space); for expression arrays in comparison, each target sequence is designed to bind to one immobilized probe at a time, with no cooperativity, on a 2-dimensional surface of a chip or bead. (Newer expression platforms typically contain probes targeting multiple regions of a gene in order to achieve higher redundancy. Notably, mismatch probes present in older microarray designs such as Affymetrix U133 are often ignored during data normalization, and they have been eliminated in newer designs such as Affymetrix Exon ST 1.0.) These properties of nanoString may potentially explain why nanoString can achieve reliable quantitation on \gls{ffpe} tissue \citeref{reis11}.

While clustering analysis has been instrumental in \emph{discovering} the molecular classes of medulloblastoma, it is ill-suited for predicting the class of a new, unknown sample. (See page \pageref{sec:classification} in the \textbf{Appendix} for the distinction between \emphterm{class discovery} and \emphterm{class prediction}.)  Clustering analysis can be sensitive to changes in sample size: removal or addition of samples can drastically influence the clustering results. The inclusion of samples with poor quality measurements may also completely reorganize the clustering structure. Moreover, clustering analysis is prone to batch effects, where the discovered classes represent different technical batches of samples and do not reflect underlying biology. In comparison, class prediction can mitigate these effects by selecting for features that discriminate between the different classes and by assessing training and testing accuracies separately. Admittedly, clustering algorithms can be adapted for class prediction, but existing classification algorithms are applied more widely, tested more extensively, and understood more deeply. Furthermore, model-based classifiers can be designed under the classification framework in order to exploit specific statistical properties of the input data and thus improve prediction accuracy. Above all, we prefer to use or refine a ready suitable tool rather than to re-purpose a tool designed for another task.

We show that our method can accurately predict the molecular subgroup of medulloblastoma samples. The method is reproducible across different nanoString service centres and across different datasets. The assays only cost about \$50 a sample. Thus, we have developed a molecular classification method for medulloblastoma that is rapid, reliable, and reproducible, and this method can be readily adopted for use in a diagnostic laboratory.


\section{Materials and methods}

\subsection{Patient samples}

All samples were obtained in accordance with the Research Ethics Board at the Hospital for Sick Children (Toronto, Canada). Primary medulloblastomas comprising the training series for nanoString ($n = 101$) have been previously described by Northcott \emph{et al.}\citeref{northcott11a} Samples contributing to the validation series ($n = 131$) were obtained from external collaborators as total RNA extracted from fresh-frozen tissue from the DKFZ (Heidelberg, Germany; Remke series, $n = 56$) \citeref{remke11}, the Dana-Farber Cancer Institute (Boston, USA; Cho series, $n = 39$) \citeref{cho11}, and Marcel Kool (DKFZ, Heidelberg, Germany; Kool series, $n = 36$) \citeref{kool08}.  \gls{ffpe} cases ($n = 84$) were obtained as paraffin sections from the Hospital for Sick Children (Toronto, Canada; $n = 34$), Johnâ€™s Hopkins University (Baltimore, USA; $n = 25$), and the DKFZ (Heidelberg, Germany; $n = 25$).

\subsection{Tissue sample processing}

Total RNA was extracted from fresh-frozen tissue using the Trizol method (Invitrogen) according to the manufacturer's instructions.  For FFPE samples, 3 to 5 paraffin sections per sample were first deparaffinized with xylene prior to RNA extraction using the RNeasy FFPE kit (Qiagen) as directed by the manufacturer.  RNA concentration was measured using a Nanodrop 1000 instrument (Nanodrop). Paul Northcott processed the samples.

\subsection{RNA integrity assessment}

RNA derived from FFPE material was analyzed with the Agilent Bioanalyzer to determine RNA integrity at \gls{tcag}. Smear analysis was performed using the Agilent 2100 expert software to determine the proportion of RNA C300 nucleotides within a given sample.

\subsection{nanoString CodeSet design and expression quantification}

Signature genes for each medulloblastoma subgroup were included in the CodeSet on the basis of their observed subgroup-specific expression as previously determined by Affymetrix exon array analysis. The CodeSet was designed to consist of a total of 25 genes with 5 to 6 signature genes included for each subgroup: WNT (\gene{WIF1}, \gene{TNC}, \gene{GAD1}, \gene{DKK2}, \gene{EMX2}), SHH (\gene{PDLIM3}, \gene{EYA1}, \gene{HHIP}, \gene{ATOH1}, \gene{SFRP1}), Group3 (\gene{IMPG2}, \gene{GABRA5}, \gene{EGFL11}, \gene{NRL}, \gene{MAB21L2}, \gene{NPR3}), Group4 (\gene{KCNA1}, \gene{EOMES}, \gene{KHDRBS2}, \gene{RBM24}, \gene{UNC5D}, \gene{OAS1}).  Three housekeeping genes (\gene{ACTB}, \gene{GAPDH}, and \gene{LDHA}) were also included in the CodeSet for biological normalization purposes. Probe sets for each gene in the CodeSet were designed and synthesized at nanoString Technologies. See Northcott \emph{et al.}\ \citeself{northcott12} for details on the subgroup-specific expression of the markers (note that Group C has been renamed Group3 and Group D has been renamed Group4 since the publication of this study).

Total RNA (100 ng) from fresh-frozen tissue and \gls{ffpe} material was analyzed using the nanoString nCounter Analysis System at the University Health Network Microarray Centre (Toronto, Canada), the Oncogenomics Core Facility at the University of Miami (Miami, USA), and the Frontiers in Genetics Facility at the University of Geneva (Geneva, Switzerland). All procedures related to mRNA quantification including sample preparation, hybridization, detection, and scanning were carried out as recommended by nanoString Technologies.

\subsection{nanoString data processing and class prediction}

Raw nanoString values were log-transformed (zero counts were mapped to zero). For each raw log\low{2} value $x^{(i)}$ in sample $i$ of $n$ total samples, the normalized value $\tilde{x}^{(i)}$ is calculated as
\[
\tilde{x}^{(i)} = x^{(i)} - p^{(i)} + p - b^{(i)} + b
\]
where $p^{(i)}$ is the mean signal from the positive control probes in sample $i$, and $b^{(i)}$ is the mean signal from the three endogenous biological control probes targeting housekeeping genes (LHDA, GAPDH, and ACTB) in sample $i$. Additionally, $p$ and $b$ are the mean positive control and biological control signals across all $n$ samples in the dataset.
\[
p = \frac{1}{n} \sum_i^n p^{(i)} \,\,\,\,\,\,
b = \frac{1}{n} \sum_i^n b^{(i)}
\]
Following normalization of nanoString counts using all samples, the normalized log2 expression values were used for downstream class prediction analysis.

A series of medulloblastomas with known subgroup affiliation ($n = 101$) were used to establish a training dataset for subsequent class prediction analysis of independent cohorts used in the study. Various class prediction algorithms were assessed by a 10-fold cross-validation scheme, using a set of scoring indices to establish a pipeline for predicting medulloblastoma subgroups with nanoString data derived from the training series. Based on superior performance in cross-validation analysis, the PAM method was selected for all downstream class prediction analyses.

All class prediction analyses were performed in the R statistical programming environment (v2.13). Implementations of the class prediction algorithms were imported from the following R packages: MASS v7.3 (linear discriminant analysis; LDA), class v7.3 (k-nearest neighbor; KNN), e1071 v1.5 (support vector machine; SVM), nnet v7.3 (multinomial log-linear model; MULT), and pamr v1.51 (prediction analysis for microarrays; PAM) \citeref{tibshirani02}. During cross-validation, the training set of 101 samples was randomly split into 10 partitions. Each class predictor was trained on nine of the partitions, and the performance of the predictor was subsequently tested on the one remaining partition. Each of the 10 partitions was used as the testing set once in a round of cross-validation. This cross-validation process was repeated for a total of 10,000 partitionings. The entire experiment was repeated at least 3 times with reproducible results.

The scoring indices used during testing were simple accuracy, Jaccard similarity index, Rand index, adjusted Rand index, and Fowlkesâ€“Mallows index. The latter four indices are different indices for determining the similarity between two groupings, which are the known and predicted classifications of samples in the current analysis. These indices serve as more stringent measures of accuracy in multiclass prediction. Aside from the aforementioned measures of accuracy, the reliability of a classifier was also determined using Shannon entropy as a measure of uncertainty:
\[
H(Y) = - \sum_{y \in Y} P(y) \; log_2 P(y)
\]
where $Y$ is taken to be the predicted class label of the classifier for a given sample. Accordingly, $P(y)$ is estimated by the empirical frequency that the classifier predicts the sample to be class $y$ across all cross-validation rounds. The mean entropy value for a classifier is averaged across all training samples.
Hence, classifiers with varying predicted classes for the same sample across cross-validation rounds have higher entropy values and are hence less reliable.

Since the model parameters for SVM can affect the prediction performance, these parameters were optimized by a grid search in a separate round of cross-validation for SVMs with linear, radial basis, polynomial, and sigmoid kernels for observations $\vect{x}_i$ and $\vect{x}_j$ as shown below.

\begin{table}[h]
	\setlength{\extrarowheight}{0.8em}
	\centering
	\begin{tabular}{l | l}
		\hline
		Kernel & $K(\vect{x}_i, \vect{x}_j)$ \\
		\hline
		linear & $\vect{x}_i^\top \vect{x}_j$ \\
		polynomial & $(\gamma \vect{x}_i^\top \vect{x}_j + r)^d$ \\
		radial basis function & $exp(-\gamma \| \vect{x}_i - \vect{x}_j \|^2)$ \\
		sigmoid & $tanh(\gamma \vect{x}_i^\top \vect{x}_j + r)$ \\
		\hline
	\end{tabular}
\end{table}
The optimal values for the kernel parameters ($\gamma > 0, r, d$) were searched in:
\[
\gamma \in \{ 2^{-15}, 2^{-13}, 2^{-11}, \ldots, 2^3 \}
\]
\[
r \in \{ -1, -0.9, -0.8, \ldots, 1 \}
\]
\[
d \in \{2, 3, 4, \ldots, 8 \}
\]
Furthermore, the optimal value for penalty parameter $C > 0$ was searched among the grid points $\{ 2^{-5}, 2^{-3}, 2^{-1}, \ldots, 2^{15} \}$. Similarly for KNN, the best model was selected from models with $k \in \{ 1, 2, \ldots, 10 \}$.

\subsection{Regression analysis of prediction accuracy}

Define $c_t$ as the number of correctly classified samples and $n_t$ as the number of samples with age $x_i \le t$
\[
n_t = \sum_i I(x_i \le t)
\]
\[
c_t = \sum_i I(x_i \le t \; \cap \; i \in \mathbb{C})
\]
where $i$ iterates over samples, $I(\cdot)$ is the indicator function, $\mathbb{C}$ is the set of correctly classified samples.
Cumulative accuracies were calculated for each sample age year bin $t$ as $y_t = c_t / n_t$, and $y_t$ was fitted as a 5-parameter logistic function of $t$, using the implementation in the drc v2.1 R package:
\[
f(t) = \gamma + \frac{\delta - \gamma}{(1 + exp( \beta (log(t) - log(\epsilon)) ))^\zeta}
\]
The maximum asymptote parameter $\delta$ was constrained at 1 in order to reflect the high accuracy that the predictor achieved with recent \gls{ffpe} samples. 

\subsection{Outlier detection}

Gaussian mixture models were fitted to the mean endogenous control signals and the mean positive control signals of all collected nanoString data to establish the reference ranges for the endogenous and positive controls. Samples with mean endogenous control or positive control signal that deviate significantly from the respective reference range at a significance level of 0.001 were identified as outliers using the one-sample $z$ test.

\section{Results}

In order to select a classification algorithm that predicts most accurately and reliably, we evaluated the class prediction performance of a panel of well-known classifiers: \gls{svm}, \gls{lda}, multinomial logistic regression, \gls{knn}, \gls{pam}. (Note that \gls{pam} is to be distinguished from the clustering algorithm, partitioning around medoids; \gls{lda} is also to be distinguished from latent Dirichlet allocation, another unsupervised learning algorithm.) These classifiers were trained on a training set of 101 fresh-frozen medulloblastoma samples with known molecular subgroups. Classifiers that have tuning parameters (\gls{svm}, \gls{pam}, and \gls{knn}) were tuned using a separate round of 10-fold cross-validation. The performance of all classifiers were assessed using repeated, stratified, 10-fold cross-validation using various measures of accuracy. \gls{pam} consistently showed superior performance to all other classifiers (\citefig{classifier-compare}). Its predictions are most consistent across multiple rounds of cross-validation, indicating that its predictions are reliable (\citefig{classifier-compare}\emphlab{d}). In comparison, multinomial logistic regression predicted different subgroups for the same sample when it was trained on different subsets of the training data, illustrating that it does not generalize well and its predictions are unreliable. Further, the test accuracy of the \gls{pam} algorithm as assessed by cross-validation was the highest (\citefig{classifier-compare}\emphlab{a-c}). Admittedly, the test accuracies of all classification algorithms were high and roughly in the same range, though \gls{pam} consistently outperformed all the other classifiers in repeated rounds of cross-validation.

\begin{figure}[hb]
	\begin{center}
		\includegraphics[width=\textwidth]{fig/nanostr-class/classifier-compare.pdf}
	\end{center}
	\caption[Cross-validation comparison of candidate classification algorithms]
	{
		Cross-validation comparison of candidate classification algorithms.
		\textbf{a-c}, Accuracy assessment of trained classifiers by repeated, stratified, 10-fold cross-validation, using measures of accuracy: (a) proportion of correctly classified samples, (b) Jaccard similarity index, and (c) adjusted Rand index.
		\textbf{d}, Consistency of trained classifiers during cross-validation, as measured by Shannon entropy. Bars represent mean Shannon entropy values averaged across all training samples.
	}
	\label{fig:classifier-compare}
\end{figure}

Therefore, we proceeded to evaluate the performance of the trained \gls{pam} classifier on external datasets of medulloblastoma samples with independently assigned molecular subgroups. The original molecular subtypes from the previous studies were mapped to the consensus molecular subgroups using the mapping detailed in the consensus report \citeref{taylor12}. The performance of the trained classifier was tested on an external set of 130 fresh-frozen medulloblastoma samples. By testing on an external validation set that is disjoint from the training set, we show that our classifier generalizes well and is insensitive to irrelevant variability across datasets. Indeed, our method achieved an overall classification accuracy of 98\% (\citefig{nanostr-valid}).

\begin{figure}[hb]
	\begin{center}
		\includegraphics[width=\textwidth]{fig/nanostr-class/nanostr-valid.pdf}
	\end{center}
	\caption[Validation of classification assay on independent medulloblastoma cohorts]
	{
	Validation of classification assay on independent medulloblastoma cohorts.
	\textbf{a-c}, Expression heatmaps of medulloblastomas of known molecular subgroup as published by Remke et al.\citeref{remke11} (a), Cho et al.\citeref{cho11} (b), and Kool et al.\citeref{kool08} (c). Samples are arranged according to subgroup predictions. Known molecular subgroups and erroneously classified cases are marked above the heatmap.
	\textbf{d}, \emph{Left}, Pie chart depicting the known subgroup distribution of medulloblastomas from the three independent cohorts analyzed in \textbf{a-c} ($n = 130$) and the subgroups predicted by nanoString profiling. Misclassified cases are marked within each slice according to the predicted subgroups. \emph{Right}, Pie chart of class prediction accuracy ($127/130$) on the validation set. Adapted from Northcott et al.\citeself{northcott12}
	}
	\label{fig:nanostr-valid}
\end{figure}

Aside from being highly accurate, our method for determining molecular subgroups is also reproducible across multiple centres. Our method yielded reproducible predictions of molecular subgroups when the same samples were processed in three independent laboratories \citeself{northcott12}.

Furthermore, our classifier, which was trained on fresh-frozen training samples, continued to predict molecular subgroups accurately on \gls{ffpe} samples. Since fresh-frozen samples are generally rare in the clinical setting and most samples are only available in \gls{ffpe} archival form, our method would need to achieve acceptable performance on \gls{ffpe} samples if it is to be used in diagnostic laboratories. Indeed, the clinical applicability of our method was demonstrated by its high predictive accuracy on \gls{ffpe} samples of archival ages $\leq 8$ years (\citefig{nanostr-ffpe}). The accuracy decreased on older \gls{ffpe} samples, presumably due to poorer RNA integrity, though standard measurements of RNA quality were not correlated with accuracy \citeself{northcott12}. Taken together, these results suggest that any fresh frozen or recent \gls{ffpe} samples may be reliably assigned molecular subgroups using our classification method.

\begin{figure}[ht]
	\begin{center}
		\includegraphics[width=\textwidth]{fig/nanostr-class/nanostr-ffpe.pdf}
	\end{center}
	\caption[Classification performance on formalin-fixed paraffin embedded archival samples]
	{
	Classification performance on \gls{ffpe} samples.
	\textbf{a}, \emph{Top}, Cumulative class prediction accuracy in relation to sample age of archival medulloblastomas stored as \gls{ffpe} material ($n = 49$). Samples obtained within the past 8 years exhibit accuracies of $\geq 95\%$. \emph{Bottom}, Frequency distribution of sample age, grouped according to prediction correctness.
	\textbf{b}, Heatmap of nanoString data showing class predictions for \gls{ffpe} cases of $\leq 8$ years confidently predicted by the assay ($n = 28$). Samples are sorted according to subgroup prediction. All cases satisfying prediction probability threshold were assigned to the correct subgroup ($28/28$). Adapted from Northcott et al.\citeself{northcott12}
	}
	\label{fig:nanostr-ffpe}
\end{figure}

Since the initial publication of this work \citeself{northcott12}, we have used the method to classify over 1000 medulloblastoma samples, of which 538 samples now have known subgroup affiliations determined from unsupervised clustering analysis on expression profiles. Using the classifier trained on the original training set ($n = 103$) to predict the subgroup of fresh-frozen samples in a non-overlapping new validation set ($n = 453$) yielded a classification accuracy of 92\%, which is lower than the accuracy previously achieved (98 \%) on the original external validation set of fresh-frozen samples ($n = 131$; \citefig{nanostr-valid}). Additionally, a few samples with replicate nanoString assays produced different class predictions. Further examination revealed that poor sample quality and suboptimal assay conditions likely contributed to errors in class prediction.

Therefore, additional quality control measures were implemented to identify unreliable results due to poor RNA quality and nanoString assay failure. Given that standard measurements of RNA quality were insufficient for predicting assay accuracy \citeself{northcott12}, the mean signals of the endogenous-control probes included in the nanoString assay were used to assess whether sufficient quantities of intact RNA were present in the samples, using an outlier detection method. Samples with low endogenous-control signal, presumably due to extensive RNA degradation, cannot be reliably assigned a molecular subgroup, and they may require repeat RNA extraction or alternative classification methods using DNA copy-number or methylation profiling. Similarly, nanoString assays may fail due to suboptimal reaction conditions (caused by pipetting error or sample contaminants). The mean signals of positive-control probes were therefore used to identify assay failures using outlier detection. The endogenous-control and positive-control quality measures helped improved accuracy on the new validation set to 94\%. Although the improvement in prediction accuracy on fresh-frozen samples is very modest, we expect a much greater improvement for \gls{ffpe} samples, which typically have much poorer RNA quality \citeref{northcott12}.

\clearpage

\section{Discussion}

We have developed and validated a reliable method for classifying medulloblastoma into molecular subgroups. Importantly, our classification method complements rather than substitutes histological diagnosis. The diagnosis of medulloblastoma from a cerebellar or posterior fossa tumour requires histological examination and exclusion of genetically defined brain tumour entities including \gls{atrt}, which is characterized by \gene{SMARCB1} mutation, and \gls{etmr}, which is characterized by amplification of the chromosome 19 microRNA cluster. Given a medulloblastoma sample, our method produces probabilities of the sample belonging to each subgroup. A sample with a low prediction probability for the most probable subgroup would warrant a second examination of its histological diagnosis. Given an unknown brain tumour sample, we would also need to entertain the possibility that a non-medulloblastoma sample may exclusively express markers that define one of the medulloblastoma subgroups. Notwithstanding these limitations, we show that our method produces reproducible results across different centres and on multiple validation datasets. Furthermore, the method performs well on \gls{ffpe} material, allowing it to be readily adopted in diagnostic laboratories. Since the publication of our classification method in Northcott \emph{et al.}\ \citeself{northcott12}, we have made additional improvements to the method. Currently, we are refining the classification method for \gls{clia} certification.

In order to reliably guide clinical decision making, we are designing classifiers that emit calibrated prediction probabilities. Presently, the trained classifier can output class probabilities that deviate from true probabilities. For example, samples that are predicted to be SHH medulloblastoma at a class probability of 99\% contain less than 99\% true SHH medulloblastoma samples; that is, more than 1\% of the predicted SHH samples at class probability $\ge$ 99\% are in fact not SHH medulloblastoma. Calibrated probabilities are desirable because they can be incorporated into the decision theory framework to achieve the optimal balance between risks and benefits of future treatments targeted against each specific molecular subgroup of medulloblastoma.

As later chapters will show, the classification of medulloblastoma into WNT, SHH, Group3, and Group4 is practically useful and catalyzes research in elucidating the molecular mechanism underlying medulloblastoma. Indeed, the molecular classification of medulloblastoma led to numerous discoveries in the community \citeself{shih14, shih12, diaz15, zhukova14, perreault14, kool14, ramaswamy14, ramaswamy13, dey13, markant13, zhukova13, remke13, dubuc13, dubuc12, wu12, jones12, rausch12, northcott11b}.


\clearpage
